#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ä½³ N å€¼è¨ˆç®—çš„ç†è«–ä¾æ“š
Statistical and Practical Foundations for Optimal N Selection

æœ¬æ–‡æª”è©³ç´°è§£é‡‹äº†åœ¨å­¸ç”Ÿäº’è©•ç³»çµ±ä¸­ï¼Œå¦‚ä½•æ ¹æ“šç­ç´šè¦æ¨¡ã€ä½œæ¥­é¡å‹å’Œå“è³ªè¦æ±‚
ä¾†è¨ˆç®—æœ€ä½³è©•å¯©æ•¸é‡ N çš„ç†è«–ä¾æ“šå’Œå¯¦å‹™è€ƒé‡ã€‚
"""

import numpy as np
import matplotlib.pyplot as plt

class StatisticalFoundations:
    """çµ±è¨ˆå­¸ç†è«–åŸºç¤"""
    
    @staticmethod
    def central_limit_theorem_demo():
        """ä¸­å¤®æ¥µé™å®šç†æ¼”ç¤ºï¼šç‚ºä»€éº¼ Nâ‰¥3 æ˜¯æœ€ä½è¦æ±‚"""
        print("ğŸ“Š ä¸­å¤®æ¥µé™å®šç†èˆ‡æœ€å°‘è©•å¯©æ•¸é‡")
        print("=" * 60)
        
        print("ç†è«–åŸºç¤ï¼š")
        print("â€¢ ç•¶ Nâ‰¥30 æ™‚ï¼Œä¸­å¤®æ¥µé™å®šç†å¼·åŠ›ç”Ÿæ•ˆ")
        print("â€¢ ç•¶ Nâ‰¥3 æ™‚ï¼Œé–‹å§‹é¡¯ç¾æ­£æ…‹åˆ†å¸ƒè¶¨å‹¢")
        print("â€¢ ç•¶ N=1-2 æ™‚ï¼Œç„¡æ³•é€²è¡Œæœ‰æ•ˆçš„çµ±è¨ˆæ¨è«–")
        
        # æ¨¡æ“¬ä¸åŒ N å€¼ä¸‹çš„ä¼°è¨ˆç²¾åº¦
        true_score = 85.0
        individual_variance = 100.0  # å€‹äººè©•åˆ†æ–¹å·®
        
        print("\nN å€¼å°ä¼°è¨ˆç²¾åº¦çš„å½±éŸ¿ï¼š")
        print("N å€¼ | æ¨™æº–èª¤å·® | 95%ä¿¡è³´å€é–“ | çµ±è¨ˆæ•ˆåŠ›")
        print("-" * 50)
        
        for n in range(1, 11):
            standard_error = np.sqrt(individual_variance / n)
            confidence_interval = 1.96 * standard_error  # 95% CI
            statistical_power = "å¾ˆä½" if n < 3 else "ä½" if n < 5 else "ä¸­ç­‰" if n < 7 else "é«˜"
            
            print(f" {n:2d}  |   {standard_error:6.2f}   |   Â±{confidence_interval:5.2f}    | {statistical_power}")
    
    @staticmethod
    def variance_reduction_analysis():
        """æ–¹å·®ç¸®æ¸›åˆ†æï¼šå¤šè©•å¯©è€…çš„çµ±è¨ˆå„ªå‹¢"""
        print("\nğŸ“‰ æ–¹å·®ç¸®æ¸›æ•ˆæ‡‰åˆ†æ")
        print("=" * 60)
        
        print("çµ±è¨ˆå­¸åŸç†ï¼š")
        print("â€¢ ç¨ç«‹è©•åˆ†çš„å¹³å‡å€¼æ–¹å·®ï¼šÏƒÂ²/N")
        print("â€¢ æ¨™æº–èª¤å·®ï¼šÏƒ/âˆšN")
        print("â€¢ æ–¹å·®ç¸®æ¸›æ¯”ä¾‹ï¼š1/N")
        
        # è¨ˆç®—ä¸åŒ N å€¼çš„æ–¹å·®ç¸®æ¸›
        base_variance = 100.0
        print("\nN å€¼çš„æ–¹å·®ç¸®æ¸›æ•ˆæœï¼š")
        print("N å€¼ | æ–¹å·®ç¸®æ¸› | ç²¾åº¦æå‡ | é‚Šéš›æ•ˆç›Š")
        print("-" * 45)
        
        previous_variance = base_variance
        for n in range(1, 11):
            variance = base_variance / n
            precision_improvement = np.sqrt(base_variance / variance)
            marginal_benefit = (previous_variance - variance) / base_variance * 100
            previous_variance = variance
            
            print(f" {n:2d}  |   {variance:6.1f}   |   {precision_improvement:4.1f}x   |   {marginal_benefit:5.1f}%")
    
    @staticmethod
    def confidence_interval_analysis():
        """ä¿¡è³´å€é–“åˆ†æï¼šå“è³ªè¦æ±‚èˆ‡ N å€¼çš„é—œä¿‚"""
        print("\nğŸ¯ ä¿¡è³´å€é–“èˆ‡å“è³ªè¦æ±‚")
        print("=" * 60)
        
        print("å“è³ªè¦æ±‚å°æ‡‰çš„çµ±è¨ˆæ¨™æº–ï¼š")
        print("â€¢ åŸºæœ¬å“è³ªï¼š80% ä¿¡è³´å€é–“ â†’ Nâ‰¥2")
        print("â€¢ æ¨™æº–å“è³ªï¼š90% ä¿¡è³´å€é–“ â†’ Nâ‰¥3")
        print("â€¢ é«˜å“è³ªï¼š95% ä¿¡è³´å€é–“ â†’ Nâ‰¥5")
        print("â€¢ é—œéµå“è³ªï¼š99% ä¿¡è³´å€é–“ â†’ Nâ‰¥7")
        
        # è¨ˆç®—ä¸åŒä¿¡è³´æ°´æº–æ‰€éœ€çš„æœ€å° N
        confidence_levels = [0.80, 0.90, 0.95, 0.99]
        z_scores = [1.28, 1.645, 1.96, 2.576]
        
        print("\nå“è³ªç­‰ç´šèˆ‡æœ€å° N å€¼è¦æ±‚ï¼š")
        print("å“è³ªç­‰ç´š  | ä¿¡è³´æ°´æº– | Zåˆ†æ•¸ | å»ºè­°æœ€å°N | å¯¦å‹™æœ€å°N")
        print("-" * 55)
        
        for i, (conf, z) in enumerate(zip(confidence_levels, z_scores)):
            quality_levels = ["åŸºæœ¬", "æ¨™æº–", "é«˜", "é—œéµ"]
            theoretical_n = max(2, int(np.ceil((z / 1.0) ** 2)))  # å‡è¨­å®¹è¨±èª¤å·®ç‚º1
            practical_n = [2, 3, 5, 7][i]  # å¯¦å‹™å»ºè­°å€¼
            
            print(f"{quality_levels[i]:8} |   {conf:.0%}   | {z:5.3f} |     {theoretical_n:2d}     |     {practical_n:2d}")

class PracticalConsiderations:
    """å¯¦å‹™è€ƒé‡å› ç´ """
    
    @staticmethod
    def workload_analysis():
        """å·¥ä½œè² æ“”åˆ†æï¼šå­¸ç”Ÿèƒ½åŠ›èˆ‡å‹•æ©Ÿè€ƒé‡"""
        print("\nâš–ï¸ å·¥ä½œè² æ“”èˆ‡å­¸ç¿’æ•ˆæœå¹³è¡¡")
        print("=" * 60)
        
        print("æ•™è‚²å¿ƒç†å­¸è€ƒé‡ï¼š")
        print("â€¢ èªçŸ¥è² è·ç†è«–ï¼šéå¤šè©•å¯©é™ä½å“è³ª")
        print("â€¢ å‹•æ©Ÿç†è«–ï¼šé©åº¦è² æ“”ç¶­æŒåƒèˆ‡åº¦")
        print("â€¢ å­¸ç¿’æ•ˆæœï¼šè©•å¯©ä»–äººä½œå“æå‡è‡ªèº«èƒ½åŠ›")
        
        # åˆ†æä¸åŒ N å€¼çš„å·¥ä½œè² æ“”
        print("\nN å€¼å°å­¸ç”Ÿå·¥ä½œè² æ“”çš„å½±éŸ¿ï¼š")
        print("N å€¼ | æ™‚é–“æˆæœ¬ | èªçŸ¥è² æ“” | åƒèˆ‡å‹•æ©Ÿ | å­¸ç¿’æ•ˆæœ")
        print("-" * 55)
        
        workload_data = [
            (1, "å¾ˆä½", "å¾ˆä½", "å¾ˆé«˜", "å¾ˆä½"),
            (2, "ä½", "ä½", "é«˜", "ä½"),
            (3, "ä¸­ç­‰", "ä¸­ç­‰", "é«˜", "ä¸­ç­‰"),
            (4, "ä¸­é«˜", "ä¸­ç­‰", "ä¸­ç­‰", "é«˜"),
            (5, "é«˜", "é«˜", "ä¸­ç­‰", "é«˜"),
            (6, "å¾ˆé«˜", "é«˜", "ä½", "ä¸­ç­‰"),
            (8, "éé«˜", "å¾ˆé«˜", "å¾ˆä½", "ä½"),
        ]
        
        for n, time, cognitive, motivation, learning in workload_data:
            print(f" {n:2d}  |   {time:4s}   |   {cognitive:4s}   |   {motivation:4s}   |   {learning:4s}")
    
    @staticmethod
    def assignment_complexity_analysis():
        """ä½œæ¥­è¤‡é›œåº¦åˆ†æï¼šä¸åŒé¡å‹ä½œæ¥­çš„è©•å¯©éœ€æ±‚"""
        print("\nğŸ“ ä½œæ¥­é¡å‹èˆ‡è©•å¯©è¤‡é›œåº¦")
        print("=" * 60)
        
        print("ä½œæ¥­é¡å‹å½±éŸ¿å› ç´ ï¼š")
        print("â€¢ è©•åˆ†æ¨™æº–æ˜ç¢ºæ€§")
        print("â€¢ ä¸»è§€åˆ¤æ–·æˆåˆ†")
        print("â€¢ è©•å¯©æ‰€éœ€å°ˆæ¥­çŸ¥è­˜")
        print("â€¢ è©•åˆ†ä¸€è‡´æ€§é›£åº¦")
        
        assignment_data = [
            ("é¸æ“‡é¡Œä½œæ¥­", "å¾ˆé«˜", "å¾ˆä½", "å¾ˆä½", "å¾ˆé«˜", 2),
            ("è¨ˆç®—é¡Œä½œæ¥­", "é«˜", "ä½", "ä½", "é«˜", 3),
            ("ç¨‹å¼è¨­è¨ˆä½œæ¥­", "ä¸­ç­‰", "ä¸­ç­‰", "ä¸­ç­‰", "ä¸­ç­‰", 3),
            ("è«–æ–‡å ±å‘Š", "ä½", "é«˜", "é«˜", "ä½", 5),
            ("å‰µæ„å°ˆæ¡ˆ", "å¾ˆä½", "å¾ˆé«˜", "é«˜", "å¾ˆä½", 6),
            ("è—è¡“ä½œå“", "å¾ˆä½", "å¾ˆé«˜", "ä¸­ç­‰", "å¾ˆä½", 6),
        ]
        
        print("\nä½œæ¥­é¡å‹å° N å€¼éœ€æ±‚çš„å½±éŸ¿ï¼š")
        print("ä½œæ¥­é¡å‹      | æ¨™æº–æ˜ç¢ºæ€§ | ä¸»è§€æˆåˆ† | å°ˆæ¥­éœ€æ±‚ | ä¸€è‡´æ€§ | å»ºè­°N")
        print("-" * 70)
        
        for assignment, clarity, subjectivity, expertise, consistency, n in assignment_data:
            print(f"{assignment:12} |   {clarity:6s}   |  {subjectivity:4s}  |  {expertise:4s}  | {consistency:4s} |  {n:2d}")
    
    @staticmethod
    def class_size_effects():
        """ç­ç´šè¦æ¨¡æ•ˆæ‡‰ï¼šç¤¾æœƒå‹•åŠ›å­¸è€ƒé‡"""
        print("\nğŸ‘¥ ç­ç´šè¦æ¨¡çš„ç¤¾æœƒå‹•åŠ›å­¸æ•ˆæ‡‰")
        print("=" * 60)
        
        print("ç­ç´šè¦æ¨¡å½±éŸ¿å› ç´ ï¼š")
        print("â€¢ åŒå„•å£“åŠ›èˆ‡ç¤¾æœƒæœŸæœ›")
        print("â€¢ åŒ¿åæ€§ç¨‹åº¦")
        print("â€¢ è©•åˆ†è€…å¤šæ¨£æ€§")
        print("â€¢ ç¤¾æœƒæ‡ˆæ€ æ•ˆæ‡‰")
        
        size_effects = [
            ("< 10äºº", "å°ç­åˆ¶", "é«˜åŒå„•å£“åŠ›", "ä½åŒ¿åæ€§", "ä½å¤šæ¨£æ€§", "ä½æ‡ˆæ€ ", "é™ä½N"),
            ("10-30äºº", "æ¨™æº–ç­åˆ¶", "ä¸­ç­‰å£“åŠ›", "ä¸­ç­‰åŒ¿åæ€§", "ä¸­ç­‰å¤šæ¨£æ€§", "ä¸­ç­‰æ‡ˆæ€ ", "æ¨™æº–N"),
            ("30-50äºº", "å¤§ç­åˆ¶", "ä½å£“åŠ›", "é«˜åŒ¿åæ€§", "é«˜å¤šæ¨£æ€§", "ä¸­ç­‰æ‡ˆæ€ ", "ç•¥å¢N"),
            ("50+äºº", "è¶…å¤§ç­åˆ¶", "å¾ˆä½å£“åŠ›", "å¾ˆé«˜åŒ¿åæ€§", "å¾ˆé«˜å¤šæ¨£æ€§", "é«˜æ‡ˆæ€ ", "é¡¯è‘—å¢N"),
        ]
        
        print("\nç­ç´šè¦æ¨¡å° N å€¼èª¿æ•´çš„å»ºè­°ï¼š")
        print("ç­ç´šè¦æ¨¡    | é¡å‹      | åŒå„•å£“åŠ›   | åŒ¿åæ€§     | å¤šæ¨£æ€§     | æ‡ˆæ€ ç¨‹åº¦ | Nå€¼èª¿æ•´")
        print("-" * 85)
        
        for size, type_name, pressure, anonymity, diversity, laziness, adjustment in size_effects:
            print(f"{size:10} | {type_name:8} | {pressure:8} | {anonymity:8} | {diversity:8} | {laziness:6} | {adjustment}")

class NOptimizationTheory:
    """N å€¼å„ªåŒ–ç†è«–"""
    
    @staticmethod
    def mathematical_foundation():
        """æ•¸å­¸åŸºç¤ï¼šæœ€ä½³ N å€¼çš„ç†è«–è¨ˆç®—"""
        print("\nğŸ”¢ N å€¼å„ªåŒ–çš„æ•¸å­¸åŸºç¤")
        print("=" * 60)
        
        print("ç›®æ¨™å‡½æ•¸ï¼šæœ€å°åŒ–ç¸½æˆæœ¬ = çµ±è¨ˆæˆæœ¬ + å·¥ä½œè² æ“”æˆæœ¬")
        print("Total_Cost(N) = Statistical_Cost(N) + Workload_Cost(N)")
        print()
        print("å…¶ä¸­ï¼š")
        print("â€¢ Statistical_Cost(N) = kâ‚ Ã— ÏƒÂ²/N  (çµ±è¨ˆèª¤å·®æˆæœ¬)")
        print("â€¢ Workload_Cost(N) = kâ‚‚ Ã— N        (å·¥ä½œè² æ“”æˆæœ¬)")
        print("â€¢ kâ‚, kâ‚‚ ç‚ºæ¬Šé‡ä¿‚æ•¸")
        
        # è¨ˆç®—æœ€ä½³ N å€¼
        k1 = 100  # çµ±è¨ˆèª¤å·®æ¬Šé‡
        k2 = 10   # å·¥ä½œè² æ“”æ¬Šé‡
        variance = 100
        
        print(f"\nç¯„ä¾‹è¨ˆç®— (kâ‚={k1}, kâ‚‚={k2}, ÏƒÂ²={variance})ï¼š")
        print("N å€¼ | çµ±è¨ˆæˆæœ¬ | å·¥ä½œæˆæœ¬ | ç¸½æˆæœ¬ | é‚Šéš›æˆæœ¬è®ŠåŒ–")
        print("-" * 60)
        
        previous_total = float('inf')
        optimal_n = 1
        min_cost = float('inf')
        
        for n in range(1, 11):
            stat_cost = k1 * variance / n
            work_cost = k2 * n
            total_cost = stat_cost + work_cost
            marginal_change = total_cost - previous_total
            
            if total_cost < min_cost:
                min_cost = total_cost
                optimal_n = n
            
            print(f" {n:2d}  |  {stat_cost:7.1f}  |  {work_cost:7.1f}  | {total_cost:7.1f} | {marginal_change:+8.1f}")
            previous_total = total_cost
        
        print(f"\nç†è«–æœ€ä½³ N å€¼ï¼š{optimal_n} (ç¸½æˆæœ¬ï¼š{min_cost:.1f})")
        
        # è§£æè§£
        analytical_n = np.sqrt(k1 * variance / k2)
        print(f"è§£æè§£æœ€ä½³ Nï¼š{analytical_n:.2f}")
    
    @staticmethod
    def adaptive_algorithm():
        """è‡ªé©æ‡‰æ¼”ç®—æ³•ï¼šå‹•æ…‹ N å€¼èª¿æ•´"""
        print("\nğŸ”„ è‡ªé©æ‡‰ N å€¼èª¿æ•´æ¼”ç®—æ³•")
        print("=" * 60)
        
        print("æ¼”ç®—æ³•åŸç†ï¼š")
        print("1. åˆå§‹è¨­å®šï¼šåŸºæ–¼ä½œæ¥­é¡å‹è¨­å®šåŸºç¤ N å€¼")
        print("2. ç­ç´šèª¿æ•´ï¼šæ ¹æ“šç­ç´šè¦æ¨¡èª¿æ•´ä¿‚æ•¸")
        print("3. å“è³ªèª¿æ•´ï¼šæ ¹æ“šå“è³ªè¦æ±‚èª¿æ•´ä¿‚æ•¸")
        print("4. é‚Šç•Œç´„æŸï¼šç¢ºä¿ N åœ¨åˆç†ç¯„åœå…§")
        
        print("\nèª¿æ•´å…¬å¼ï¼š")
        print("N_optimal = ceil(N_base Ã— size_factor Ã— quality_factor)")
        print("N_final = max(2, min(N_optimal, class_size-1, 10))")
        
        # ç¤ºç¯„è¨ˆç®—
        test_cases = [
            ("homework", 25, "standard", 3, 1.0, 1.0),
            ("exam", 15, "high", 4, 0.8, 1.2),
            ("project", 40, "critical", 5, 1.2, 1.5),
            ("essay", 8, "standard", 6, 0.7, 1.0),
        ]
        
        print("\nå¯¦éš›è¨ˆç®—ç¯„ä¾‹ï¼š")
        print("ä½œæ¥­é¡å‹  | ç­ç´š | å“è³ªè¦æ±‚ | åŸºç¤N | è¦æ¨¡ä¿‚æ•¸ | å“è³ªä¿‚æ•¸ | æœ€ä½³N")
        print("-" * 70)
        
        for assignment, class_size, quality, base_n, size_factor, quality_factor in test_cases:
            optimal_n = int(np.ceil(base_n * size_factor * quality_factor))
            final_n = max(2, min(optimal_n, class_size - 1, 10))
            
            print(f"{assignment:8} | {class_size:2d}äºº | {quality:8} |  {base_n:2d}  |   {size_factor:.1f}    |   {quality_factor:.1f}    |  {final_n:2d}")

def generate_recommendation_matrix():
    """ç”Ÿæˆ N å€¼å»ºè­°çŸ©é™£"""
    print("\nğŸ“‹ N å€¼å»ºè­°çŸ©é™£")
    print("=" * 60)
    
    assignment_types = ["homework", "exam", "programming", "project", "essay"]
    class_sizes = [5, 15, 25, 40, 60]
    quality_levels = ["basic", "standard", "high", "critical"]
    
    print("å»ºè­° N å€¼çŸ©é™£ (ä½œæ¥­é¡å‹ Ã— ç­ç´šè¦æ¨¡)ï¼š")
    print("(å‡è¨­æ¨™æº–å“è³ªè¦æ±‚)")
    print()
    
    # æ§‹å»ºè¡¨æ ¼æ¨™é¡Œ
    header = "ä½œæ¥­é¡å‹\\ç­ç´šè¦æ¨¡  |"
    for size in class_sizes:
        header += f"  {size:2d}äºº"
    print(header)
    print("-" * len(header))
    
    base_n_values = {"homework": 3, "exam": 4, "programming": 3, "project": 5, "essay": 6}
    
    for assignment in assignment_types:
        row = f"{assignment:15s} |"
        base_n = base_n_values[assignment]
        
        for size in class_sizes:
            if size < 10:
                size_factor = 0.8
            elif size < 30:
                size_factor = 1.0
            elif size < 50:
                size_factor = 1.2
            else:
                size_factor = 1.4
            
            optimal_n = int(np.ceil(base_n * size_factor))
            final_n = max(2, min(optimal_n, size - 1, 10))
            row += f"   {final_n:2d}"
        print(row)

def main():
    """ä¸»å‡½æ•¸ï¼šå±•ç¤ºæ‰€æœ‰ç†è«–ä¾æ“š"""
    print("ğŸ“ å­¸ç”Ÿäº’è©•ç³»çµ±æœ€ä½³ N å€¼è¨ˆç®—çš„ç†è«–ä¾æ“š")
    print("=" * 80)
    print("Statistical and Practical Foundations for Optimal N Selection")
    print("in Peer Assessment Systems")
    print()
    
    # çµ±è¨ˆå­¸åŸºç¤
    StatisticalFoundations.central_limit_theorem_demo()
    StatisticalFoundations.variance_reduction_analysis()
    StatisticalFoundations.confidence_interval_analysis()
    
    # å¯¦å‹™è€ƒé‡
    PracticalConsiderations.workload_analysis()
    PracticalConsiderations.assignment_complexity_analysis()
    PracticalConsiderations.class_size_effects()
    
    # å„ªåŒ–ç†è«–
    NOptimizationTheory.mathematical_foundation()
    NOptimizationTheory.adaptive_algorithm()
    
    # å»ºè­°çŸ©é™£
    generate_recommendation_matrix()
    
    print("\n" + "=" * 80)
    print("ğŸ“š ç†è«–ä¾æ“šç¸½çµï¼š")
    print("1. çµ±è¨ˆå­¸åŸºç¤ï¼šä¸­å¤®æ¥µé™å®šç†ã€æ–¹å·®ç¸®æ¸›ã€ä¿¡è³´å€é–“")
    print("2. æ•™è‚²å¿ƒç†å­¸ï¼šèªçŸ¥è² è·ç†è«–ã€å‹•æ©Ÿç†è«–ã€å­¸ç¿’æ•ˆæœ")
    print("3. ç¤¾æœƒå‹•åŠ›å­¸ï¼šåŒå„•å£“åŠ›ã€åŒ¿åæ€§ã€ç¤¾æœƒæ‡ˆæ€ æ•ˆæ‡‰")
    print("4. æœ€ä½³åŒ–ç†è«–ï¼šæˆæœ¬æ•ˆç›Šåˆ†æã€å¤šç›®æ¨™å„ªåŒ–")
    print("5. å¯¦å‹™ç´„æŸï¼šæ™‚é–“é™åˆ¶ã€èƒ½åŠ›é™åˆ¶ã€åƒèˆ‡åº¦ç¶­æŒ")
    
    print("\nğŸ’¡ é—œéµåŸå‰‡ï¼š")
    print("â€¢ çµ±è¨ˆå¯é æ€§ï¼šNâ‰¥3 ä¿è­‰åŸºæœ¬çµ±è¨ˆæ„ç¾©")
    print("â€¢ å¯¦å‹™å¯è¡Œæ€§ï¼šNâ‰¤8 é¿å…éåº¦å·¥ä½œè² æ“”")
    print("â€¢ å‹•æ…‹èª¿æ•´ï¼šæ ¹æ“šå…·é«”æƒ…æ³éˆæ´»èª¿æ•´")
    print("â€¢ æŒçºŒç›£æ§ï¼šè©•ä¼°æ•ˆæœä¸¦å„ªåŒ–åƒæ•¸")

if __name__ == "__main__":
    main()
