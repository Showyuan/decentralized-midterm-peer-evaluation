#!/usr/bin/env python3
"""
çµæœæ”¶é›†å™¨ (Web ç‰ˆæœ¬)
å¾è³‡æ–™åº«æ”¶é›†è©•åˆ†çµæœä¸¦è¼¸å‡ºç‚º JSON å’Œ Excel æ ¼å¼
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List
from collections import defaultdict

from stage2_db_manager import DatabaseManager

try:
    import openpyxl
    from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
    from openpyxl.utils import get_column_letter
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False
    print("âš ï¸  è­¦å‘Š: openpyxl æœªå®‰è£ï¼Œç„¡æ³•è¼¸å‡º Excel æª”æ¡ˆ")


class ResultCollectorWeb:
    """å¾è³‡æ–™åº«æ”¶é›†è©•åˆ†çµæœ"""
    
    def __init__(self):
        self.db = DatabaseManager()
        
        # å¾é…ç½®ç²å–è·¯å¾‘
        try:
            from stage0_config_unified import PeerEvaluationConfig
        except ImportError:
            from .stage0_config_unified import PeerEvaluationConfig
        
        self.config = PeerEvaluationConfig()
        self.output_dir = Path(self.config.ensure_output_dir('stage5_results'))
        
        # è¼‰å…¥å­¸ç”Ÿè³‡æ–™
        self.students = self._load_student_data()
    
    def _load_student_data(self) -> Dict:
        """è¼‰å…¥å­¸ç”Ÿè³‡æ–™"""
        data_path = Path(self.config.get_path('stage1_output', 'processed_data'))
        
        if data_path.exists():
            with open(data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('students', {})
        
        return {}
    
    def collect_results(self) -> Dict:
        """
        æ”¶é›†æ‰€æœ‰è©•åˆ†çµæœ
        
        Returns:
            Dict: åŒ…å«æ‰€æœ‰è©•åˆ†çµæœçš„å­—å…¸
        """
        print("=" * 80)
        print("ğŸ“Š é–‹å§‹å¾è³‡æ–™åº«æ”¶é›†è©•åˆ†çµæœ")
        print("=" * 80)
        
        # ç²å–æ‰€æœ‰æäº¤è¨˜éŒ„
        submissions = self.db.get_all_submissions()
        
        print(f"ğŸ“ ç¸½æäº¤è¨˜éŒ„æ•¸: {len(submissions)}")
        
        # æŒ‰è¢«è©•åˆ†è€…çµ„ç¹”æ•¸æ“š
        results_by_target = defaultdict(lambda: {
            'evaluations': [],
            'questions': defaultdict(list)
        })
        
        for submission in submissions:
            target_id = submission['target_id']
            evaluator_id = submission['evaluator_id']
            question_id = submission['question_id']
            score = submission['score']
            comment = submission['comment']
            
            # è¨˜éŒ„è©•åˆ†
            results_by_target[target_id]['evaluations'].append({
                'evaluator_id': evaluator_id,
                'question_id': question_id,
                'score': score,
                'comment': comment,
                'submitted_at': submission['submitted_at']
            })
            
            # æŒ‰é¡Œç›®åˆ†çµ„
            results_by_target[target_id]['questions'][question_id].append({
                'evaluator_id': evaluator_id,
                'score': score,
                'comment': comment
            })
        
        # çµ±è¨ˆæ¯å€‹å­¸ç”Ÿçš„çµæœ
        final_results = {}
        
        for target_id, data in results_by_target.items():
            # ç²å–å­¸ç”Ÿè³‡è¨Š
            student_info = self.students.get(target_id, {})
            student_name = student_info.get('name', target_id)
            
            # è¨ˆç®—æ¯é¡Œçš„çµ±è¨ˆ
            question_stats = {}
            total_scores = []
            
            for question_id in sorted(data['questions'].keys()):
                scores = [item['score'] for item in data['questions'][question_id]]
                comments = [item['comment'] for item in data['questions'][question_id] if item['comment']]
                
                question_stats[question_id] = {
                    'scores': scores,
                    'mean': round(sum(scores) / len(scores), 2),
                    'min': min(scores),
                    'max': max(scores),
                    'count': len(scores),
                    'comments': comments
                }
                
                total_scores.extend(scores)
            
            # è¨ˆç®—ç¸½åˆ†çµ±è¨ˆ
            final_results[target_id] = {
                'student_id': target_id,
                'student_name': student_name,
                'total_evaluations': len(set(e['evaluator_id'] for e in data['evaluations'])),
                'total_scores': len(total_scores),
                'overall_mean': round(sum(total_scores) / len(total_scores), 2) if total_scores else 0,
                'overall_min': min(total_scores) if total_scores else 0,
                'overall_max': max(total_scores) if total_scores else 0,
                'question_stats': question_stats,
                'all_evaluations': data['evaluations']
            }
        
        # ç”ŸæˆåŒ¯ç¸½çµ±è¨ˆ
        summary = self._generate_summary(final_results)
        
        result = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'total_students': len(final_results),
                'total_submissions': len(submissions),
                'total_evaluations': len(submissions) // 5,  # æ¯ä»½è©•åˆ†æœ‰ 5 é¡Œ
            },
            'summary': summary,
            'results': final_results
        }
        
        return result
    
    def _generate_summary(self, results: Dict) -> Dict:
        """ç”ŸæˆåŒ¯ç¸½çµ±è¨ˆ"""
        
        all_means = [data['overall_mean'] for data in results.values()]
        
        # æŒ‰å•é¡Œçµ±è¨ˆ
        question_summary = defaultdict(list)
        for data in results.values():
            for q_id, stats in data['question_stats'].items():
                question_summary[q_id].append(stats['mean'])
        
        summary = {
            'overall': {
                'mean': round(sum(all_means) / len(all_means), 2) if all_means else 0,
                'min': round(min(all_means), 2) if all_means else 0,
                'max': round(max(all_means), 2) if all_means else 0,
            },
            'by_question': {}
        }
        
        for q_id, means in question_summary.items():
            summary['by_question'][q_id] = {
                'mean': round(sum(means) / len(means), 2),
                'min': round(min(means), 2),
                'max': round(max(means), 2),
            }
        
        return summary
    
    def export_to_json(self, results: Dict, filename: str = None) -> Path:
        """
        åŒ¯å‡ºçµæœç‚º JSON æª”æ¡ˆ
        
        Args:
            results: çµæœå­—å…¸
            filename: æª”æ¡ˆåç¨±ï¼ˆå¯é¸ï¼‰
            
        Returns:
            Path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        if filename is None:
            # ä½¿ç”¨é…ç½®ç”Ÿæˆæª”æ¡ˆè·¯å¾‘
            output_path = Path(self.config.get_path('stage5_results', 'evaluation_results_json', timestamp=datetime.now()))
        else:
            output_path = self.output_dir / filename
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… çµæœå·²åŒ¯å‡º: {output_path}")
        print(f"   æª”æ¡ˆå¤§å°: {output_path.stat().st_size / 1024:.2f} KB")
        
        return output_path
    
    def export_for_vancouver(self, results: Dict) -> Path:
        """
        åŒ¯å‡ºç‚º Vancouver ç³»çµ±ç›¸å®¹æ ¼å¼
        
        Vancouver ç®—æ³•æœŸæœ›çš„æ ¼å¼ï¼š
        {
            "summary_stats": {...},
            "evaluation_data": [
                {
                    "evaluator_id": "A01",
                    "evaluations": {
                        "B02": 20,  // ç¸½åˆ† (Q1+Q2+Q3+Q4+Q5)
                        "C03": 18,
                        ...
                    }
                }
            ]
        }
        
        Args:
            results: çµæœå­—å…¸
            
        Returns:
            Path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        print("\nğŸ“Š ç”Ÿæˆ Vancouver ç®—æ³•è¼¸å…¥æ ¼å¼...")
        
        # æ­¥é©Ÿ 1: å½™ç¸½æ¯å€‹è©•åˆ†è€…å°æ¯å€‹è¢«è©•åˆ†è€…çš„æ‰€æœ‰å•é¡Œåˆ†æ•¸
        evaluator_scores = defaultdict(lambda: defaultdict(int))  # {evaluator_id: {target_id: total_score}}
        question_count = defaultdict(lambda: defaultdict(int))     # {evaluator_id: {target_id: question_count}}
        
        for target_id, data in results['results'].items():
            for eval_data in data['all_evaluations']:
                evaluator_id = eval_data['evaluator_id']
                score = eval_data['score']
                
                # ç´¯åŠ åˆ†æ•¸
                evaluator_scores[evaluator_id][target_id] += score
                question_count[evaluator_id][target_id] += 1
        
        # æ­¥é©Ÿ 2: ç”Ÿæˆ Vancouver æ ¼å¼çš„ evaluation_data
        evaluation_data = []
        for evaluator_id in sorted(evaluator_scores.keys()):
            evaluations_dict = {}
            for target_id, total_score in evaluator_scores[evaluator_id].items():
                evaluations_dict[target_id] = total_score
            
            evaluation_data.append({
                'evaluator_id': evaluator_id,
                'evaluations': evaluations_dict
            })
        
        # æ­¥é©Ÿ 3: ç”Ÿæˆçµ±è¨ˆæ‘˜è¦
        all_scores = []
        for evaluator_data in evaluation_data:
            all_scores.extend(evaluator_data['evaluations'].values())
        
        summary_stats = {
            'total_evaluators': len(evaluation_data),
            'total_evaluations': sum(len(e['evaluations']) for e in evaluation_data),
            'total_scores': len(all_scores),
            'average_score': sum(all_scores) / len(all_scores) if all_scores else 0,
            'overall_stats': {
                'mean': sum(all_scores) / len(all_scores) if all_scores else 0,
                'min': min(all_scores) if all_scores else 0,
                'max': max(all_scores) if all_scores else 0
            }
        }
        
        # æ­¥é©Ÿ 4: çµ„åˆæœ€çµ‚è³‡æ–™
        vancouver_data = {
            'summary_stats': summary_stats,
            'evaluation_data': evaluation_data
        }
        
        # ä½¿ç”¨é…ç½®ç”Ÿæˆæª”æ¡ˆè·¯å¾‘
        output_path = Path(self.config.get_path('stage5_results', 'vancouver_input', timestamp=datetime.now()))
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(vancouver_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Vancouver æ ¼å¼å·²åŒ¯å‡º: {output_path}")
        print(f"   â€¢ è©•åˆ†è€…æ•¸é‡: {summary_stats['total_evaluators']}")
        print(f"   â€¢ è©•åˆ†ç¸½æ•¸: {summary_stats['total_evaluations']}")
        print(f"   â€¢ å¹³å‡ç¸½åˆ†: {summary_stats['average_score']:.2f}")
        
        return output_path
    
    def export_to_excel(self, results: Dict, filename: str = None) -> Path:
        """
        åŒ¯å‡ºçµæœç‚º Excel æª”æ¡ˆ
        
        Args:
            results: çµæœå­—å…¸
            filename: æª”æ¡ˆåç¨±ï¼ˆå¯é¸ï¼‰
            
        Returns:
            Path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        if not EXCEL_AVAILABLE:
            print("âŒ ç„¡æ³•åŒ¯å‡º Excel: openpyxl æœªå®‰è£")
            print("   è«‹åŸ·è¡Œ: pip install openpyxl")
            return None
        
        if filename is None:
            # ä½¿ç”¨é…ç½®ç”Ÿæˆæª”æ¡ˆè·¯å¾‘
            output_path = Path(self.config.get_path('stage5_results', 'evaluation_results_xlsx', timestamp=datetime.now()))
        else:
            output_path = self.output_dir / filename
        
        # å»ºç«‹å·¥ä½œç°¿
        wb = openpyxl.Workbook()
        
        # æ¨£å¼å®šç¾©
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(color="FFFFFF", bold=True)
        center_alignment = Alignment(horizontal="center", vertical="center")
        border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # å·¥ä½œè¡¨ 1: æ‘˜è¦çµ±è¨ˆ
        ws_summary = wb.active
        ws_summary.title = "æ‘˜è¦çµ±è¨ˆ"
        
        metadata = results['metadata']
        summary = results['summary']
        
        # å¯«å…¥æ‘˜è¦è³‡è¨Š
        ws_summary['A1'] = "è©•åˆ†çµæœæ‘˜è¦"
        ws_summary['A1'].font = Font(size=16, bold=True)
        ws_summary.merge_cells('A1:D1')
        
        row = 3
        ws_summary[f'A{row}'] = "ç”Ÿæˆæ™‚é–“:"
        ws_summary[f'B{row}'] = metadata['generated_at']
        row += 1
        
        ws_summary[f'A{row}'] = "å­¸ç”Ÿç¸½æ•¸:"
        ws_summary[f'B{row}'] = metadata['total_students']
        row += 1
        
        ws_summary[f'A{row}'] = "è©•åˆ†ç¸½æ•¸:"
        ws_summary[f'B{row}'] = metadata['total_evaluations']
        row += 1
        
        ws_summary[f'A{row}'] = "è¨˜éŒ„ç¸½æ•¸:"
        ws_summary[f'B{row}'] = metadata['total_submissions']
        row += 2
        
        # æ•´é«”çµ±è¨ˆ
        ws_summary[f'A{row}'] = "æ•´é«”åˆ†æ•¸çµ±è¨ˆ"
        ws_summary[f'A{row}'].font = Font(bold=True)
        row += 1
        
        ws_summary[f'A{row}'] = "å¹³å‡åˆ†"
        ws_summary[f'B{row}'] = summary['overall']['mean']
        row += 1
        
        ws_summary[f'A{row}'] = "æœ€ä½åˆ†"
        ws_summary[f'B{row}'] = summary['overall']['min']
        row += 1
        
        ws_summary[f'A{row}'] = "æœ€é«˜åˆ†"
        ws_summary[f'B{row}'] = summary['overall']['max']
        row += 2
        
        # å„é¡Œçµ±è¨ˆ
        ws_summary[f'A{row}'] = "å„é¡Œå¹³å‡åˆ†"
        ws_summary[f'A{row}'].font = Font(bold=True)
        row += 1
        
        # è¡¨é ­
        ws_summary[f'A{row}'] = "å•é¡Œ"
        ws_summary[f'B{row}'] = "å¹³å‡åˆ†"
        ws_summary[f'C{row}'] = "æœ€ä½åˆ†"
        ws_summary[f'D{row}'] = "æœ€é«˜åˆ†"
        for col in ['A', 'B', 'C', 'D']:
            ws_summary[f'{col}{row}'].fill = header_fill
            ws_summary[f'{col}{row}'].font = header_font
            ws_summary[f'{col}{row}'].alignment = center_alignment
        row += 1
        
        for q_id in sorted(summary['by_question'].keys()):
            stats = summary['by_question'][q_id]
            ws_summary[f'A{row}'] = q_id
            ws_summary[f'B{row}'] = stats['mean']
            ws_summary[f'C{row}'] = stats['min']
            ws_summary[f'D{row}'] = stats['max']
            row += 1
        
        # å·¥ä½œè¡¨ 2: å­¸ç”Ÿè©³ç´°çµæœ
        ws_details = wb.create_sheet("å­¸ç”Ÿè©³ç´°çµæœ")
        
        headers = ["å­¸ç”ŸID", "å§“å", "è©•åˆ†æ•¸", "ç¸½è¨˜éŒ„æ•¸", "å¹³å‡åˆ†", "æœ€ä½åˆ†", "æœ€é«˜åˆ†", 
                   "Q1å¹³å‡", "Q2å¹³å‡", "Q3å¹³å‡", "Q4å¹³å‡", "Q5å¹³å‡"]
        
        for col_idx, header in enumerate(headers, 1):
            cell = ws_details.cell(row=1, column=col_idx, value=header)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = center_alignment
            cell.border = border
        
        row = 2
        for target_id in sorted(results['results'].keys()):
            data = results['results'][target_id]
            
            ws_details.cell(row=row, column=1, value=data['student_id'])
            ws_details.cell(row=row, column=2, value=data['student_name'])
            ws_details.cell(row=row, column=3, value=data['total_evaluations'])
            ws_details.cell(row=row, column=4, value=data['total_scores'])
            ws_details.cell(row=row, column=5, value=data['overall_mean'])
            ws_details.cell(row=row, column=6, value=data['overall_min'])
            ws_details.cell(row=row, column=7, value=data['overall_max'])
            
            # å„é¡Œå¹³å‡
            for q_idx, q_id in enumerate(['Q1', 'Q2', 'Q3', 'Q4', 'Q5'], 8):
                if q_id in data['question_stats']:
                    ws_details.cell(row=row, column=q_idx, 
                                  value=data['question_stats'][q_id]['mean'])
            
            # æ·»åŠ é‚Šæ¡†
            for col_idx in range(1, len(headers) + 1):
                ws_details.cell(row=row, column=col_idx).border = border
                ws_details.cell(row=row, column=col_idx).alignment = center_alignment
            
            row += 1
        
        # å·¥ä½œè¡¨ 3: æ‰€æœ‰è©•åˆ†è¨˜éŒ„
        ws_all = wb.create_sheet("æ‰€æœ‰è©•åˆ†è¨˜éŒ„")
        
        headers = ["è©•åˆ†è€…ID", "è¢«è©•åˆ†è€…ID", "è¢«è©•åˆ†è€…å§“å", "å•é¡ŒID", "åˆ†æ•¸", "è©•è«–", "æäº¤æ™‚é–“"]
        
        for col_idx, header in enumerate(headers, 1):
            cell = ws_all.cell(row=1, column=col_idx, value=header)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = center_alignment
            cell.border = border
        
        row = 2
        for target_id in sorted(results['results'].keys()):
            data = results['results'][target_id]
            
            for eval_data in sorted(data['all_evaluations'], 
                                   key=lambda x: (x['evaluator_id'], x['question_id'])):
                ws_all.cell(row=row, column=1, value=eval_data['evaluator_id'])
                ws_all.cell(row=row, column=2, value=target_id)
                ws_all.cell(row=row, column=3, value=data['student_name'])
                ws_all.cell(row=row, column=4, value=eval_data['question_id'])
                ws_all.cell(row=row, column=5, value=eval_data['score'])
                ws_all.cell(row=row, column=6, value=eval_data['comment'])
                ws_all.cell(row=row, column=7, value=eval_data['submitted_at'])
                
                for col_idx in range(1, len(headers) + 1):
                    ws_all.cell(row=row, column=col_idx).border = border
                
                row += 1
        
        # èª¿æ•´åˆ—å¯¬
        for ws in [ws_summary, ws_details, ws_all]:
            for column_cells in ws.columns:
                length = max(len(str(cell.value or "")) for cell in column_cells)
                ws.column_dimensions[get_column_letter(column_cells[0].column)].width = min(length + 2, 50)
        
        # å„²å­˜
        wb.save(output_path)
        
        print(f"âœ… Excel æª”æ¡ˆå·²åŒ¯å‡º: {output_path}")
        print(f"   æª”æ¡ˆå¤§å°: {output_path.stat().st_size / 1024:.2f} KB")
        print(f"   å·¥ä½œè¡¨: æ‘˜è¦çµ±è¨ˆ, å­¸ç”Ÿè©³ç´°çµæœ, æ‰€æœ‰è©•åˆ†è¨˜éŒ„")
        
        return output_path
    
    def print_summary(self, results: Dict):
        """åˆ—å°çµæœæ‘˜è¦"""
        print("\n" + "=" * 80)
        print("ğŸ“Š è©•åˆ†çµæœæ‘˜è¦")
        print("=" * 80)
        
        metadata = results['metadata']
        summary = results['summary']
        
        print(f"\nåŸºæœ¬çµ±è¨ˆ:")
        print(f"  å­¸ç”Ÿç¸½æ•¸: {metadata['total_students']}")
        print(f"  è©•åˆ†ç¸½æ•¸: {metadata['total_evaluations']}")
        print(f"  è¨˜éŒ„ç¸½æ•¸: {metadata['total_submissions']}")
        
        print(f"\næ•´é«”åˆ†æ•¸:")
        print(f"  å¹³å‡åˆ†: {summary['overall']['mean']}")
        print(f"  æœ€ä½åˆ†: {summary['overall']['min']}")
        print(f"  æœ€é«˜åˆ†: {summary['overall']['max']}")
        
        print(f"\nå„é¡Œå¹³å‡åˆ†:")
        for q_id, stats in sorted(summary['by_question'].items()):
            print(f"  {q_id}: {stats['mean']} (ç¯„åœ: {stats['min']}-{stats['max']})")
        
        print("\n" + "=" * 80)


def main():
    """ä¸»å‡½æ•¸"""
    collector = ResultCollectorWeb()
    
    # æ”¶é›†çµæœ
    results = collector.collect_results()
    
    # åˆ—å°æ‘˜è¦
    collector.print_summary(results)
    
    # åŒ¯å‡º JSON
    json_path = collector.export_to_json(results)
    
    # åŒ¯å‡º Excel
    excel_path = collector.export_to_excel(results)
    
    # åŒ¯å‡º Vancouver æ ¼å¼
    vancouver_path = collector.export_for_vancouver(results)
    
    print("\nâœ… çµæœæ”¶é›†å®Œæˆï¼")
    print(f"\nè¼¸å‡ºæª”æ¡ˆ:")
    print(f"  1. å®Œæ•´çµæœ (JSON): {json_path}")
    if excel_path:
        print(f"  2. å®Œæ•´çµæœ (Excel): {excel_path}")
    print(f"  3. Vancouver æ ¼å¼: {vancouver_path}")


if __name__ == '__main__':
    main()
