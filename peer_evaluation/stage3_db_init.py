#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬ - å‰µå»ºè³‡æ–™åº«ä¸¦å°å…¥ Tokens
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ°è·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

from stage2_db_manager import DatabaseManager
from stage0_config_unified import PeerEvaluationConfig


def find_latest_token_file(tokens_dir: str) -> str:
    """
    æ‰¾åˆ°æœ€æ–°çš„ token æ–‡ä»¶
    
    Args:
        tokens_dir: Token ç›®éŒ„è·¯å¾‘
        
    Returns:
        æœ€æ–°çš„ token æ–‡ä»¶è·¯å¾‘
    """
    token_files = list(Path(tokens_dir).glob("evaluation_tokens_*.json"))
    if not token_files:
        raise FileNotFoundError(f"åœ¨ {tokens_dir} ä¸­æ‰¾ä¸åˆ° token æ–‡ä»¶")
    
    # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼Œè¿”å›æœ€æ–°çš„
    latest_file = max(token_files, key=lambda p: p.stat().st_mtime)
    return str(latest_file)


def load_student_data(data_file: str) -> dict:
    """
    è¼‰å…¥å­¸ç”Ÿè³‡æ–™
    
    Args:
        data_file: å­¸ç”Ÿè³‡æ–™æ–‡ä»¶è·¯å¾‘
        
    Returns:
        å­¸ç”Ÿè³‡æ–™å­—å…¸
    """
    with open(data_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data.get('students', {})


def import_tokens_to_db(db_manager: DatabaseManager, token_file: str, students_data: dict):
    """
    å°‡ tokens å°å…¥è³‡æ–™åº«
    
    Args:
        db_manager: è³‡æ–™åº«ç®¡ç†å™¨
        token_file: Token æ–‡ä»¶è·¯å¾‘
        students_data: å­¸ç”Ÿè³‡æ–™
    """
    print(f"\nğŸ“¥ è®€å– Token æ–‡ä»¶: {token_file}")
    
    with open(token_file, 'r', encoding='utf-8') as f:
        token_data = json.load(f)
    
    tokens_dict = token_data.get('tokens', {})
    
    print(f"âœ“ æ‰¾åˆ° {len(tokens_dict)} ä½å­¸ç”Ÿçš„ Tokens")
    
    # é¦–å…ˆå°å…¥å­¸ç”Ÿè³‡æ–™åˆ° students è¡¨
    print(f"\nğŸ“¥ å°å…¥å­¸ç”Ÿè³‡æ–™åˆ° students è¡¨...")
    student_count = 0
    with db_manager.get_connection() as conn:
        cursor = conn.cursor()
        for student_id, student_info in students_data.items():
            try:
                cursor.execute("""
                    INSERT OR IGNORE INTO students (student_id, student_name, email)
                    VALUES (?, ?, ?)
                """, (
                    student_id,
                    student_info.get('name', student_id),
                    student_info.get('email', f'{student_id}@example.com')
                ))
                if cursor.rowcount > 0:
                    student_count += 1
            except Exception as e:
                print(f"âš ï¸  å­¸ç”Ÿ {student_id} æ’å…¥å¤±æ•—: {e}")
        conn.commit()
    
    print(f"âœ“ æˆåŠŸå°å…¥ {student_count} ä½å­¸ç”Ÿè³‡æ–™")
    
    # æº–å‚™æ‰¹æ¬¡å°å…¥çš„ token åˆ—è¡¨
    tokens_to_import = []
    
    for evaluator_id, tokens in tokens_dict.items():
        # ç²å–å­¸ç”Ÿè³‡è¨Š
        student_info = students_data.get(evaluator_id, {})
        evaluator_name = student_info.get('name', evaluator_id)
        email = student_info.get('email', f'{evaluator_id}@example.com')
        
        for token_obj in tokens:
            token_dict = {
                'token': token_obj['token'],
                'evaluator_id': evaluator_id,
                'evaluator_name': evaluator_name,
                'email': email,
                'target_id': token_obj['target_id'],
                'questions': token_obj['questions'],
                'created_at': token_obj['created_at'],
                'expires_at': token_obj['expires_at'],
                'status': token_obj.get('status', 'pending'),
                'used': token_obj.get('used', False)
            }
            tokens_to_import.append(token_dict)
    
    # æ‰¹æ¬¡å°å…¥ tokens
    print(f"\nâ³ å°å…¥ {len(tokens_to_import)} å€‹ Tokens åˆ°è³‡æ–™åº«...")
    success_count, fail_count = db_manager.save_tokens_batch(tokens_to_import)
    
    print(f"\nâœ… Token å°å…¥å®Œæˆ:")
    print(f"   â€¢ æˆåŠŸ: {success_count} å€‹")
    print(f"   â€¢ å¤±æ•—/å·²å­˜åœ¨: {fail_count} å€‹")
    print(f"   â€¢ ç¸½è¨ˆ: {len(tokens_to_import)} å€‹")


def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 60)
    print("è³‡æ–™åº«åˆå§‹åŒ–èˆ‡ Token å°å…¥")
    print("=" * 60)
    
    # è¼‰å…¥é…ç½®
    config = PeerEvaluationConfig()
    
    try:
        # æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å·²å­˜åœ¨ä¸”æœ‰è³‡æ–™
        db_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            "workflow_results/4_database/evaluation.db"
        )
        
        db_exists = os.path.exists(db_path)
        tokens_exist = False
        
        if db_exists:
            print(f"\nâš ï¸  æª¢æ¸¬åˆ°è³‡æ–™åº«å·²å­˜åœ¨: {db_path}")
            # æª¢æŸ¥æ˜¯å¦æœ‰ tokens
            import sqlite3
            try:
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                cursor.execute('SELECT COUNT(*) FROM tokens')
                token_count = cursor.fetchone()[0]
                conn.close()
                
                if token_count > 0:
                    tokens_exist = True
                    print(f"   è³‡æ–™åº«ä¸­å·²æœ‰ {token_count} å€‹ Tokens")
                    print("\n" + "=" * 60)
                    print("âš ï¸  è³‡æ–™åº«å·²å­˜åœ¨ä¸”åŒ…å«è³‡æ–™")
                    print("=" * 60)
                    print("\né¸é …:")
                    print("  1. è·³éåˆå§‹åŒ– (ä¿ç•™ç¾æœ‰è³‡æ–™)")
                    print("  2. é‡æ–°åˆå§‹åŒ– (æœƒæ¸…ç©ºæ‰€æœ‰è³‡æ–™)")
                    print("  3. åƒ…å°å…¥æ–° Tokens (ä¿ç•™ç¾æœ‰ Tokens)")
                    
                    choice = input("\nè«‹é¸æ“‡ [1/2/3, é è¨­=1]: ").strip() or "1"
                    
                    if choice == "1":
                        print("\nâœ… è·³éåˆå§‹åŒ–ï¼Œä¿ç•™ç¾æœ‰è³‡æ–™")
                        print(f"\nè³‡æ–™åº«ä½ç½®: {db_path}")
                        print(f"Token æ•¸é‡: {token_count}")
                        return 0
                    elif choice == "2":
                        print("\nâš ï¸  å°‡åˆªé™¤ç¾æœ‰è³‡æ–™åº«ä¸¦é‡æ–°åˆå§‹åŒ–...")
                        confirm = input("ç¢ºå®šè¦ç¹¼çºŒå—? [y/N]: ").strip().lower()
                        if confirm != 'y':
                            print("âŒ æ“ä½œå·²å–æ¶ˆ")
                            return 0
                        os.remove(db_path)
                        print("âœ… èˆŠè³‡æ–™åº«å·²åˆªé™¤")
                    elif choice == "3":
                        print("\nâœ… å°‡å°å…¥æ–° Tokens (è·³éå·²å­˜åœ¨çš„)")
                        # ç¹¼çºŒåŸ·è¡Œï¼Œä½†ä¸é‡æ–°åˆå§‹åŒ–è³‡æ–™åº«
                    else:
                        print("âŒ ç„¡æ•ˆçš„é¸é …")
                        return 1
            except Exception as e:
                print(f"   æª¢æŸ¥è³‡æ–™åº«æ™‚å‡ºéŒ¯: {e}")
                print("   å°‡ç¹¼çºŒåˆå§‹åŒ–...")
        
        # 1. åˆå§‹åŒ–è³‡æ–™åº«ç®¡ç†å™¨ (æœƒè‡ªå‹•å‰µå»ºè³‡æ–™åº«)
        if not db_exists or not tokens_exist:
            print("\nğŸ”§ åˆå§‹åŒ–è³‡æ–™åº«...")
        else:
            print("\nğŸ”§ é€£æ¥è³‡æ–™åº«...")
        
        db_manager = DatabaseManager()
        
        if not db_exists:
            print(f"âœ… è³‡æ–™åº«å‰µå»ºæˆåŠŸ: {db_manager.db_path}")
        else:
            print(f"âœ… è³‡æ–™åº«é€£æ¥æˆåŠŸ: {db_manager.db_path}")
        
        # 2. æ‰¾åˆ°æœ€æ–°çš„ token æ–‡ä»¶
        tokens_dir = config.ensure_output_dir('stage3_tokens')
        token_file = find_latest_token_file(tokens_dir)
        
        # 3. è¼‰å…¥å­¸ç”Ÿè³‡æ–™
        print("\nğŸ“š è¼‰å…¥å­¸ç”Ÿè³‡æ–™...")
        student_data_file = config.get_path('stage1_output', 'processed_data')
        students_data = load_student_data(student_data_file)
        print(f"âœ“ è¼‰å…¥ {len(students_data)} ä½å­¸ç”Ÿè³‡æ–™")
        
        # 4. å°å…¥ tokens
        import_tokens_to_db(db_manager, token_file, students_data)
        
        # 5. é¡¯ç¤ºè³‡æ–™åº«çµ±è¨ˆ
        print("\n" + "=" * 60)
        print("ğŸ“Š è³‡æ–™åº«çµ±è¨ˆ")
        print("=" * 60)
        
        with db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # Token çµ±è¨ˆ
            cursor.execute("SELECT COUNT(*) FROM tokens")
            total_tokens = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE status = 'pending'")
            pending_tokens = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE is_used = 1")
            used_tokens = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM tokens WHERE datetime(expires_at) < datetime('now')")
            expired_tokens = cursor.fetchone()[0]
            
            # æäº¤çµ±è¨ˆ
            cursor.execute("SELECT COUNT(*) FROM submissions")
            total_submissions = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(DISTINCT evaluator_id) FROM tokens")
            unique_evaluators = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(DISTINCT target_id) FROM tokens")
            unique_targets = cursor.fetchone()[0]
        
        print(f"  â€¢ Token ç¸½æ•¸: {total_tokens}")
        print(f"  â€¢ å¾…ä½¿ç”¨: {pending_tokens}")
        print(f"  â€¢ å·²ä½¿ç”¨: {used_tokens}")
        print(f"  â€¢ å·²éæœŸ: {expired_tokens}")
        print(f"  â€¢ æäº¤ç¸½æ•¸: {total_submissions}")
        print(f"  â€¢ è©•åˆ†è€…æ•¸: {unique_evaluators}")
        print(f"  â€¢ è¢«è©•è€…æ•¸: {unique_targets}")
        
        print("\n" + "=" * 60)
        print("âœ… è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ")
        print("=" * 60)
        print(f"\nè³‡æ–™åº«ä½ç½®: {db_manager.db_path}")
        print(f"Web ç®¡ç†é é¢: https://ntublockchainintro2025.online")
        
        return 0
        
    except FileNotFoundError as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        print("   è«‹å…ˆåŸ·è¡Œ stage2_token_generator.py ç”Ÿæˆ tokens")
        return 1
    except Exception as e:
        print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
